{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a intruction on how to apply our benchmark for you own task. This illustration covers the tasks of:**\\\n",
    "\n",
    "**1. Model Development:**\\\n",
    "**(1) Gpaph node embedding task**\\\n",
    "**(2) Graph-wise embedding task**\\\n",
    "**(3) Sequence embedding task**\\\n",
    "**(4) Sequence geneerative task**\n",
    "\n",
    "**2. Bioinformatic development:**\\\n",
    "**(1) Protein structure representation task**\\\n",
    "**(2) Protein sequence representation task**\\\n",
    "**(3) Topology/Structure based protein design task**\\\n",
    "**(4) Antibody design task**\n",
    "\n",
    "**By going through this tutorial you will be familiar with our datasets, data structure and how to applly our pipeline for training and evaluation. The user development modules are mark with \"User Defined\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoading import Dataloader\n",
    "import networks\n",
    "import training_helper\n",
    "import evaluation_helper\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology / Structure-based Protein Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database: SCOPe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Discriminative Tasks:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|            | class | fold | super-family | family | protein |\n",
    "| ---        | ---   | ---  | ---          | ---    |  ---    |\n",
    "| Training   | 6     | 1080 | 1820         | 4304   | 40082   |\n",
    "| Validation | 6     | 771  | 1232         | 2705   | 10069   |\n",
    "| Test       | 6     | 902  | 1480         | 3373   | 10737   |\n",
    "| All        | 6     | 1080 | 1820         | 4304   | 60888   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Generative Task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|            | class | fold | super-family | family | protein |\n",
    "| ---        | ---   | ---  | ---          | ---    |  ---    |\n",
    "| Training   | 6     | 870  | 1367         | 3022   | 39979   |\n",
    "| Validation | 6     | 131  | 276          | 678    | 10678   |\n",
    "| Test       | 6     | 152  | 259          | 662    | 10231   |\n",
    "| All        | 6     | 1080 | 1820         | 4304   | 60888   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Task\n",
    "**Test the node or graph-wise graph embedding models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize the dataloader as the following shows. For the first time the dataloader will directly download the processed data from the website. For the following attempts it will diretly load the downloaded data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the database...\n",
      "Downloading 1wc9o9p7nyg8s95_MO-UI80qqKVoSf4L9 into ../Datasets/SCOPe/SCOPe.zip... Done.\n",
      "Unzipping...Done.\n",
      "\n",
      "Database: SCOPe\n",
      "Task: Discriminative\n",
      "Shuffle: True False False\n",
      "training: 40082 samples\n",
      "validation: 10069 samples\n",
      "test: 10737 samples\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "train_set, vali_set, test_set = Dataloader(database = 'SCOPe', \n",
    "                                           path = '../Datasets/SCOPe/', \n",
    "                                           task = 'Discriminative', \n",
    "                                           batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For simiplicity here we only load part of the dataset. For the challenge please apply the complete dataset (database = 'SCOPe_debug').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the database...\n",
      "Downloading 1BFsBdQzLiRKmc1lDOZBwREcCnfg4EiRU into ../Datasets/SCOPe/SCOPe_debug.zip... Done.\n",
      "Unzipping...Done.\n",
      "\n",
      "Database: SCOPe_debug\n",
      "Task: Discriminative\n",
      "Shuffle: True False False\n",
      "training: 55 samples\n",
      "validation: 55 samples\n",
      "test: 59 samples\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "train_set, vali_set, test_set = Dataloader(database = 'SCOPe_debug', \n",
    "                                           path = '../Datasets/SCOPe/', \n",
    "                                           task = 'Discriminative', \n",
    "                                           batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model (user defined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Firstly users need to define their own GNN, and then they can take the class *GraphLevelEmbedding* as a container for their model. Then they can do the discriminative task following our pipeline. The GNN can only take the feature vector (max_num_of_nodes x feat_dim) and the adjacency tensor (channel_num x max_num_of_nodes x max_num_of_nodes). In this task max_num_of_nodes = 60, feat_dim = 11; channel_num = 5 for heterogeneous graph and 1 for heterogenous graph. The GNN can be either node-wise or graph-wise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a node-wise embedding graph (the part need to be defined by users)\n",
    "gnn = networks.GraphConvolNetwork(feature_dim = 11, hidden_dim = 100, embedding_dim = 20, \n",
    "                                  num_layers = 3, channel_num=5)\n",
    "# This is an illustration implementation of the GCN and the inputs are not necessary, \n",
    "# but the input feature dimension must be 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The container of the GNN. \n",
    "model_dis = networks.GNN_Container(model = gnn, embedding_dim = 20, \n",
    "                                   pooling = 'max', CUDA = False, channel_num=5)\n",
    "# embedding dim x channel_num = output dimension of the defined GNN\n",
    "# For node-wise GNN, \"pooling\" can be 'max', 'sum' or 'mean'; for graph-wise GNN \"pooling\" need to be set as None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Average loss: 2.410692\n",
      "Training accuracy: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.0000\n",
      "Training time for Epoch 1: 0.5225 s\n",
      "Total time for Epoch 1: 0.9112 s\n",
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.620403\n",
      "Training accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.0000\n",
      "Training time for Epoch 2: 0.5063 s\n",
      "Total time for Epoch 2: 0.8715 s\n",
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.172347\n",
      "Training accuracy: 0.8545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.0000\n",
      "Training time for Epoch 3: 0.4726 s\n",
      "Total time for Epoch 3: 0.8412 s\n",
      "Best training result: 0.8545 (epoch 3)\n",
      "Best validation result: 0.0000 (epoch 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_dis, optimizer, results = training_helper.discriminative_train(train_set, # training set\n",
    "                                                                     model_dis, # model \n",
    "                                                                     num_epochs = 3, # amount of epochs\n",
    "                                                                     val_dataset=vali_set, # val set (optional)\n",
    "                                                                     test_dataset=None, # test set (optional)\n",
    "                                                                     heterogeous = True, # False for homogeneous graph\n",
    "                                                                     USE_CUDA = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prec': 0.0, 'recall': 0.0, 'acc': 0.0, 'F1': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zoro/Applications/Anaconda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluation_helper.Disc_evaluate(test_set, model_dis, heterogeous=True, USE_CUDA = False)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Task\n",
    "**Test node-wise graph embedding models in a sequence generation task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database SCOPe_debug has already been downloaded.\n",
      "\n",
      "Database: SCOPe_debug\n",
      "Task: Generative\n",
      "Shuffle: True False False\n",
      "training: 68 samples\n",
      "validation: 89 samples\n",
      "test: 59 samples\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "train_set, vali_set, test_set = Dataloader(database = 'SCOPe_debug', \n",
    "                                           path = '../Datasets/SCOPe/', \n",
    "                                           task = 'Generative', \n",
    "                                           batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"gnn\" was already defined above\n",
    "model_gen = networks.VAE_Container(gnn_model = gnn, gnn_out_dim = 100, CUDA=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Average-Loss: 2.9342\tAverage-CE: 2.9340\tAverage-KLD: 0.2962\n",
      "Training time: 7.2537s\n",
      "Epoch 2:\n",
      "Average-Loss: 2.7058\tAverage-CE: 2.7051\tAverage-KLD: 0.3352\n",
      "Training time: 7.8602s\n",
      "Epoch 3:\n",
      "Average-Loss: 2.5504\tAverage-CE: 2.5492\tAverage-KLD: 0.3738\n",
      "Training time: 7.8868s\n"
     ]
    }
   ],
   "source": [
    "model_gen, optimizer_gen = training_helper.VAE_training(model_gen, train_set, Epoch_NUM = 3,\n",
    "                                                        heterogeous = True, USE_CUDA = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity is 14.3335.\n",
      "The average sequence identity is 0.0301.\n",
      "\n",
      "Examples of the generated sequences:\n",
      "EEKKQLVMMYMMMLMYMYYHHHMHYMYHHHHYHHMYHYHHMYYYHYHHYEHHSKKVKVSSEEQLQENVNNNVHNHNHHHVNNHNNHNVNVHVVVHNVNHVIFQ\n",
      "CCCKKYYYESSEMMCTTCMMMMTCCTTCTCTMTCCMMMMMMMTMCCTEEGDVGGMMKKKGVQLKLLSLSLKLSKSLKSSSLLKSSLKLKSLLLKSKSWWWVWWPPMWPWPWPPWMMWMWWPMMPMWMPPWPWMHWWMMTTTVTNPTTPPKMMPMEELLEEEELSSSSSSSELELEESSEEESSSELEESHKH\n",
      "HMHHTIIDEEEFHHFFHFTHEHDQEKEEDIFMGAYNNNNY\n",
      "YYAPEMS\n",
      "NNPPNIMIIIYASASAASAAFYYHQQQHYYQYQYHQYQYYHQQYYQYYYYHQHYQYSSFFLSSSLMMSSVQQGGTTTTTTICMMHHAHHHVMRMMRNHEFWATNNHFQEQQEEQ\n",
      "EGVITFTNTTEESDSMTTTIMMTTMTMTMTMIMTIIMMITIMMIMMMTMMMMWMVVNVNEHHSSDRRRDDDRDMMMMDRMRDRMRDRDDRMRDRDRDDRSEEEMDDMHIHHHQTDTTTDTTHDDDMMMDMMTTSS\n",
      "GFFQQEQQE\n",
      "HASASSWTNDDSNNYRYYRRRRNRRRNNNNRRNRYYYNYYNYYRRNNDMMMQMDQDQDDDMDMMMDMDMMMMMMMQQDDQDD\n",
      "MKSSKKSDNNEETATTHKKHHKHKHTEIIDYEDDMDFMM\n",
      "SSSLSHIIESGSGGTSSGGTSGGTTSGTGGTSGSSSSSTTGSSGGTTTTTTNNHMYYYMYMEEEEHQMTMMMTVIKKAHMPMDGMVVKMVMVMVVKMMKVKVVMVVVKMKVKVKKKVVK\n"
     ]
    }
   ],
   "source": [
    "ele_all, seq_all, iden_list, ppl_list = evaluation_helper.Gen_evaluation(model_gen, train_set,\n",
    "                                                                         heterogeous = True, \n",
    "                                                                         USE_CUDA = False)\n",
    "print('The perplexity is %.4f.'%(float(torch.mean(torch.Tensor(ppl_list)))))\n",
    "print('The average sequence identity is %.4f.'%(np.mean(iden_list)))\n",
    "print()\n",
    "print('Examples of the generated sequences:')\n",
    "for s in  seq_all[:10]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity is 15.1727.\n",
      "The average sequence identity is 0.0244.\n",
      "\n",
      "Examples of the generated sequences:\n",
      "FSSSKMEHHEFMFFYHT\n",
      "AKAAKMMTTVMMVMVVMTTMTMMVTTVVTMTMMTTMMVMTMMYKHTTKTTKTTTHTHHHHHTKHKHHHKTTTTHHKHTFWWQQSAAAHRMGMMMSQQNNEIS\n",
      "SSSPPKKPTWWHMIHIIHYIIIIIIYYYHYHHHIHHHYIHIIHHIIHYK\n",
      "TKEVVEESLTTTKSTTSTTSKTSSSTTSKSTTSSKKKTSKTKSTDTTPLLTKKA\n",
      "SKSKSSETNHTTLLESI\n",
      "LMYYFYFYYWFWFFYWYWYWFFFFFWWWYWFWYYFYYNLLMMMT\n",
      "AQQVIHWMWWMWGMWWMGMWMMWMWGWWWMMMMWMWWGMGMRNTRTNRTRTRTTRTNNNRNTRNTNNTRNRTRTTN\n",
      "EETTMFTTMMMFFTMTMFTTFMMMFFMMMTMMMMFMFMFADDDAADWVEEEVEEEEEHVEVVHVVEHEEEEHEVVEEHVHVVPPPGGGIIITTTLETVNTTTTTTNLTLTLLLTTTNNNTLLTNTNNVQT\n",
      "LLYLWDDMDRDRDMMDMMRMDRMDMRMMDDMMMDDRRDMDASSSLEELSSLLSLSEESLLLESSESLELESSSESLWA\n",
      "QWLMYSSTHTTDMMDHHEHWRRRRREVEVEVV\n"
     ]
    }
   ],
   "source": [
    "ele_all, seq_all, iden_list, ppl_list = evaluation_helper.Gen_evaluation(model_gen, test_set,\n",
    "                                                                         heterogeous = True, \n",
    "                                                                         USE_CUDA = False)\n",
    "print('The perplexity is %.4f.'%(float(torch.mean(torch.Tensor(ppl_list)))))\n",
    "print('The average sequence identity is %.4f.'%(np.mean(iden_list)))\n",
    "print()\n",
    "print('Examples of the generated sequences:')\n",
    "for s in  seq_all[:10]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
